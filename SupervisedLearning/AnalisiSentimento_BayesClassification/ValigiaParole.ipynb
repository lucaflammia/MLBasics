{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-# -*- c \n",
    "\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "stopwords = set(stopwords.words('english') + stopwords.words('italian'))\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "def bagOfWords(stringa):\n",
    "    \"\"\"\n",
    "    Partiziona la stringa in un elenco di parole.\n",
    "    rimuove spazi, caratteri di punteggiatura,\n",
    "    url, stop words, menzioni (@) e 'RT'.\n",
    "    Trasforma tutte le maiuscole in minuscole.\n",
    "    \"\"\"\n",
    "    words = stringa.lower().strip().split(' ')\n",
    "    for word in words:\n",
    "        word = word.rstrip().lstrip()\n",
    "        if not re.match(r'^https?:\\/\\/.*[\\r\\n]*', word) \\\n",
    "        and not re.match(r'^http?:\\/\\/.*[\\r\\n]*', word) \\\n",
    "        and not re.match('^@.*', word) \\\n",
    "        and not re.match('\\s', word) \\\n",
    "        and word not in stopwords \\\n",
    "        and word != 'rt':\n",
    "            word = regex.sub(\"\", word)\n",
    "            if word:\n",
    "                yield word\n",
    "\n",
    "class NaiveBayesClassifier(object):\n",
    "\n",
    "    def __init__(self, k=1):\n",
    "        self.diz_parole = {}\n",
    "        self.prob_classi = {}\n",
    "        self.k = k\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        \"\"\"\n",
    "        In questa funzione, X e Y saranno due array (liste).\n",
    "        - X contiene tutte le bag of words\n",
    "          di tutti i tweet già classificati.\n",
    "          Es. X = [ \n",
    "                    ['casa', 'bellissima', 'comprare'], \n",
    "                    ['agenzia', 'costi'], ...\n",
    "                  ]\n",
    "        - Y invece contiene le classi a cui appartengono i tweet: \n",
    "          - 0 = Sentiment Negativo\n",
    "          - 1 = Sentiment Positivo\n",
    "          Es. Y = [1, 0, 0, 1, 0, 1, 1, ...]\n",
    "\n",
    "        Questa funzione non ritorna niente, serve a creare\n",
    "        il dizionario di parole con il numero delle occorrenze\n",
    "        relative alla classe. \n",
    "        \"\"\"\n",
    "        classi_distinte = set(Y)\n",
    "\n",
    "        for lista, classe in zip(X, Y):\n",
    "            for parola in lista:\n",
    "                self.diz_parole.setdefault(parola, defaultdict(int))[classe] += 1\n",
    "\n",
    "        tot_generale = sum(x[0]+x[1] for x in \n",
    "                           self.diz_parole.values())\n",
    "\n",
    "        for classe in classi_distinte:\n",
    "            tot_classe = sum(lista[classe] for lista in\n",
    "                             self.diz_parole.values())\n",
    "            self.prob_classi[classe] = tot_classe / float(tot_generale)\n",
    "\n",
    "    def classify(self, X):\n",
    "        \"\"\"\n",
    "        Questa funzione sarà quella usata per classificare\n",
    "        i nuovi tweet. \n",
    "\n",
    "        X è una lista di liste come per la funzione di addestramento.\n",
    "        Questo ci permetterà di catalogare più di un tweet\n",
    "        per volta\n",
    "\n",
    "        Ritorna una lista con le classi di appartenza dei tweet, \n",
    "        ovvero: 1 se il tweet esprime un sentimento positivo,\n",
    "        0 altrimenti.\n",
    "        \"\"\"\n",
    "        risultato = []\n",
    "        for tweet in X:\n",
    "            prob_per_classe = {}\n",
    "            for classe in self.prob_classi:\n",
    "                tot_classe = sum(lista[classe] for lista in\n",
    "                             self.diz_parole.values())\n",
    "                \n",
    "                prob = math.exp(\n",
    "                    sum([math.log(self.prob_classi[classe])] + \n",
    "                        [math.log(((self.k + self.diz_parole.get(w, {}).get(classe, 0)) / \n",
    "                            (2*self.k + float(tot_classe)))) for w in tweet])\n",
    "                    )\n",
    "                prob_per_classe[classe] = prob\n",
    "            classe_max = next(k for k, v in prob_per_classe.items() \n",
    "                            if v == max(prob for prob in \n",
    "                                prob_per_classe.values()))\n",
    "            risultato.append(classe_max)\n",
    "        return risultato\n",
    "    \n",
    "\n",
    "with open('data.json') as f:\n",
    "    data = json.loads(f.read())\n",
    "    \n",
    "nb = NaiveBayesClassifier()\n",
    "X = [list(bagOfWords(t)) for t in data['X']]\n",
    "nb.train(X, data['Y'])\n",
    "\n",
    "tweets = [\n",
    "    \"Oggi sarà una bellissima giornata, me lo sento!\",\n",
    "    \"Questo piatto non mi piace, è troppo salato\",\n",
    "    \"Il lavoro è interessante, credo accetterò la loro offerta\",\n",
    "    \"Mi sarebbe piaciuto andare al concerto, ma non ho trovato i biglietti\"\n",
    "]\n",
    "\n",
    "tweets = [list(bagOfWords(t)) for t in tweets]\n",
    "print(nb.classify(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
