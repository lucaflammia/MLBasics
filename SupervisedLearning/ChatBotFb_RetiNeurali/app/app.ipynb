{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/Nov/2020 17:40:56] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sqlite3\n",
    "import requests\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import ItalianStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tflearn import input_data, fully_connected, regression, DNN\n",
    "\n",
    "from flask import Flask, request\n",
    "\n",
    "# TOKEN = \"EAAOTXsXg5kwBAIXtxYKiPSKZA3BxV9pxZBDXZBrmCrW6I4qi2VbToKtgm1I1XzaOUfz1RjgBNOziza3oKZCSWlBzxM0axkjOE9IZAlYB4vhI4IJJMFOuBpGSlOUfnIH8iBF6DQ1UZCVFuYPiLvZBCADN8r4cJmtIKthTfsF0ZADC6AZDZD\"\n",
    "TOKEN = \"EAALlnc8E2GEBAAjriTLp0juNZCCASTwjiPhSCxuqaYorNvXBQaA8h6ZBIFb9UoEPI8p5uaom4XP6QrPTggD7EzWpPFExBPZBrID8vf61VWpf3Fl8sUArRX1xSeAyhQlA7KWxAmeYON3YOjoLNzwXVPCyqILZCkBmiGGZBPRatZAQZDZD\"\n",
    "VERIFY_TOKEN = 'TESTINGTOKEN'\n",
    "# istanzio un'applicazione Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# leggo i dati dal corpus\n",
    "d = pickle.load(open(\"corpus.p\", \"rb\"))\n",
    "temi = d['temi']\n",
    "classi = d['classi']\n",
    "documenti = d['documenti']\n",
    "\n",
    "# mi connetto al db\n",
    "database = \"bot.db\"\n",
    "conn = sqlite3.connect(database)\n",
    "cursor = conn.cursor()\n",
    "stemmer = ItalianStemmer()\n",
    "stop = set(stopwords.words('italian'))\n",
    "\n",
    "def genera_temi(testo):\n",
    "    stop = set(stopwords.words('italian'))\n",
    "    lista_parole = word_tokenize(testo)\n",
    "    temi = [\n",
    "        stemmer.stem(p.lower()) for p in lista_parole\n",
    "        if p not in stop and p not in string.punctuation\n",
    "    ]\n",
    "    return temi\n",
    "\n",
    "def genera_input(lista_temi):\n",
    "    lista_input = [0] * len(temi)\n",
    "    for tema in lista_temi:\n",
    "        for i, t in enumerate(temi):\n",
    "            if t == tema:\n",
    "                lista_input[i] = 1\n",
    "    return (np.array(lista_input))\n",
    "\n",
    "def BotANN():\n",
    "    tf.reset_default_graph()\n",
    "    rete = input_data(shape=[None, len(temi)])\n",
    "    rete = fully_connected(rete, 8)\n",
    "    rete = fully_connected(rete, 8)\n",
    "    rete = fully_connected(rete, len(classi), activation='softmax')\n",
    "    rete = regression(rete)\n",
    "    model = DNN(rete, tensorboard_dir='logs')\n",
    "    return model\n",
    "\n",
    "modello = BotANN()\n",
    "modello.load(\"./rete\")\n",
    "\n",
    "SOGLIA_ERRORE = 0.25\n",
    "\n",
    "def classifica(modello, array):\n",
    "    # genera le probabilità\n",
    "    prob = modello.predict([array])[0]\n",
    "    # filtro quelle che superano la soglia\n",
    "    risultati = [\n",
    "        [i,p] for i,p in enumerate(prob)\n",
    "        if p > SOGLIA_ERRORE\n",
    "    ]\n",
    "    # ordino per le classi più probabili\n",
    "    risultati.sort(key=lambda x: x[1], reverse=True)\n",
    "    lista_classi = []\n",
    "    for r in risultati:\n",
    "        lista_classi.append((list(classi)[r[0]], r[1]))\n",
    "    return lista_classi\n",
    "\n",
    "def invia(utente, messaggio):\n",
    "    params = {\n",
    "        \"access_token\": TOKEN\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = json.dumps({\n",
    "            \"recipient\": {\n",
    "                \"id\": utente\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"text\": messaggio\n",
    "            }\n",
    "    })\n",
    "    requests.post(\n",
    "        \"https://graph.facebook.com/v2.6/me/messages\",\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "        data=data\n",
    "    )\n",
    "\n",
    "def elabora_risposta(frase, utente=\"utente_prova\"):\n",
    "    temi_frase = genera_temi(frase)\n",
    "    X = genera_input(temi_frase)\n",
    "    classi_predette = classifica(modello, X)\n",
    "    # tolgo le probabilità\n",
    "    classi_predette = [c[0] for c in classi_predette]\n",
    "    if classi_predette:\n",
    "        # ho un contesto settato?\n",
    "        if contesti.get(utente):\n",
    "            contesto = contesti[utente]\n",
    "            # quali classi hanno questo contesto?\n",
    "            q = \"\"\"\n",
    "                SELECT classe FROM classi\n",
    "                INNER JOIN contesti ON (classi.id = contesti.id_classe)\n",
    "                WHERE classe IN ({})\n",
    "                \"\"\".format(\",\".join(\n",
    "                    \"'{}'\".format(classe) for classe in classi_predette\n",
    "            )\n",
    "            )\n",
    "            filtro_classi = [c[0] for c in cursor.execute(q).fetchall()]\n",
    "            if filtro_classi:\n",
    "                # ho almeno una classe predetta che usa un contesto\n",
    "                classi_predette = [c for c in classi_predette]\n",
    "\n",
    "        # leggo le risposte\n",
    "        q = \"\"\"\n",
    "            SELECT risposta\n",
    "            FROM risposte\n",
    "            INNER JOIN classi ON (risposte.id_classe = classi.id)\n",
    "            WHERE classe = '{0}'\n",
    "        \"\"\".format(classi_predette[0])\n",
    "        risposte = [r[0] for r in cursor.execute(q).fetchall()]\n",
    "\n",
    "        # scelgo una risposta\n",
    "        risposta = np.random.choice(risposte)\n",
    "\n",
    "        # imposto il contesto, se c'è\n",
    "        q = \"\"\"\n",
    "            SELECT contesto from contesti\n",
    "            INNER JOIN classi ON (contesti.id_classe = classi.id)\n",
    "            INNER JOIN risposte ON (risposte.id_classe = classi.id)\n",
    "            WHERE risposta = \"{}\"\n",
    "        \"\"\".format(risposta)\n",
    "        contesto = cursor.execute(q).fetchone()\n",
    "        contesti[utente] = contesto[0] if contesto else None\n",
    "\n",
    "        return risposta\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def risponditore():\n",
    "    if request.method == 'GET':\n",
    "        if request.args.get(\"hub.mode\") == \"subscribe\" and \\\n",
    "        request.args.get(\"hub.challenge\"):\n",
    "            if not request.args.get(\"hub.verify_token\") == TOKEN:\n",
    "                return \"Token errato\", 403\n",
    "            return request.args[\"hub.challenge\"], 200\n",
    "    #\n",
    "        return \"Sono un bot, non un sito web\", 200\n",
    "    else:\n",
    "        # è appena arrivato un messaggio\n",
    "        data = request.get_json()\n",
    "        if data[\"object\"] == \"page\":\n",
    "            for entry in data[\"entry\"]:\n",
    "                for messaging_event in entry[\"messaging\"]:\n",
    "                    utente = messaging_event[\"sender\"][\"id\"]\n",
    "                    domanda = messaging_event[\"message\"][\"text\"]\n",
    "                    risposta = elabora_risposta(domanda, utente)\n",
    "                    invia(utente, risposta)\n",
    "        return \"ho risposto\", 200\n",
    "        #\n",
    "        # token_inviato = request.args.get(\"hub.verify_token\")\n",
    "        # return verifica_fb_token(token_inviato)\n",
    "\n",
    "        # return \"Sono un bot, non un sito web {}\".format(request.args), 200\n",
    "    # elif request.method == 'POST':\n",
    "    #     # è appena arrivato un messaggio\n",
    "    #     data = request.get_json()\n",
    "    #     if data[\"object\"] == \"page\":\n",
    "    #         for entry in data[\"entry\"]:\n",
    "    #             for messaging_event in entry[\"messaging\"]:\n",
    "    #                 utente = messaging_event[\"sender\"][\"id\"]\n",
    "    #                 domanda = messaging_event[\"message\"][\"text\"]\n",
    "    #                 risposta = elabora_risposta(domanda, utente)\n",
    "    #                 invia(utente, risposta)\n",
    "    #     return \"ho risposto\", 200\n",
    "\n",
    "def verifica_fb_token(token_sent):\n",
    "    # take token sent by Facebook and verify it matches the verify token you sent\n",
    "    # if they match, allow the request, else return an error\n",
    "    if token_sent == VERIFY_TOKEN:\n",
    "        return request.args.get(\"hub.challenge\")\n",
    "    # return 'Invalid verification token {0} {1}'.format(token_sent, VERIFY_TOKEN)\n",
    "    return request.args.get(\"hub.challenge\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
