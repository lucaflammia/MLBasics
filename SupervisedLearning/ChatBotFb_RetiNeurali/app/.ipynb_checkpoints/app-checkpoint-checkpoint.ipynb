{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nNewRandomAccessFile failed to Create/Open: C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete.data-00000-of-00001 : Impossibile trovare il file specificato.\r\n; No such file or directory\n\t [[node save_1/RestoreV2 (defined at C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:147) ]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8dee4dd732cd>\", line 63, in <module>\n    modello = BotANN()\n  File \"<ipython-input-1-8dee4dd732cd>\", line 60, in BotANN\n    model = DNN(rete, tensorboard_dir='logs')\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\models\\dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py\", line 147, in __init__\n    allow_empty=True)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in __init__\n    self.build()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1571, in restore_v2\n    name=name)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nNewRandomAccessFile failed to Create/Open: C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete.data-00000-of-00001 : Impossibile trovare il file specificato.\r\n; No such file or directory\n\t [[node save_1/RestoreV2 (defined at C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:147) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete.data-00000-of-00001 : Impossibile trovare il file specificato.\r\n; No such file or directory\n\t [[{{node save_1/RestoreV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1275\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1276\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1277\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete.data-00000-of-00001 : Impossibile trovare il file specificato.\r\n; No such file or directory\n\t [[node save_1/RestoreV2 (defined at C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:147) ]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8dee4dd732cd>\", line 63, in <module>\n    modello = BotANN()\n  File \"<ipython-input-1-8dee4dd732cd>\", line 60, in BotANN\n    model = DNN(rete, tensorboard_dir='logs')\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\models\\dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py\", line 147, in __init__\n    allow_empty=True)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in __init__\n    self.build()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1571, in restore_v2\n    name=name)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): NewRandomAccessFile failed to Create/Open: C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete.data-00000-of-00001 : Impossibile trovare il file specificato.\r\n; No such file or directory\n\t [[node save_1/RestoreV2 (defined at C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:147) ]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1285\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1286\u001b[1;33m         \u001b[0mnames_to_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[1;34m(checkpoint_path)\u001b[0m\n\u001b[0;32m   1590\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[1;32m-> 1591\u001b[1;33m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[0;32m   1592\u001b[0m   object_graph_proto = (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[1;34m(self, tensor_str)\u001b[0m\n\u001b[0;32m    369\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[1;32m--> 370\u001b[1;33m                                           status)\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8dee4dd732cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mmodello\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBotANN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mmodello\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./rete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mSOGLIA_ERRORE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, model_file, weights_only, **optargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m                      \u001b[0mcreated\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrestored\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \"\"\"\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         self.predictor = Evaluator([self.net],\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, model_file, trainable_variable_only, variable_name_map, scope_for_restore, create_new_session, verbose)\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[0mrestorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtrainable_variable_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestorer_trainvars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1290\u001b[0m         \u001b[1;31m# a helpful message (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[1;32m-> 1292\u001b[1;33m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[0;32m   1293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[1;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nNewRandomAccessFile failed to Create/Open: C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete.data-00000-of-00001 : Impossibile trovare il file specificato.\r\n; No such file or directory\n\t [[node save_1/RestoreV2 (defined at C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:147) ]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8dee4dd732cd>\", line 63, in <module>\n    modello = BotANN()\n  File \"<ipython-input-1-8dee4dd732cd>\", line 60, in BotANN\n    model = DNN(rete, tensorboard_dir='logs')\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\models\\dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py\", line 147, in __init__\n    allow_empty=True)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in __init__\n    self.build()\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1571, in restore_v2\n    name=name)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nNewRandomAccessFile failed to Create/Open: C:\\Users\\Utente\\Documents\\Energee3\\ML_projects\\heroku-app\\rete.data-00000-of-00001 : Impossibile trovare il file specificato.\r\n; No such file or directory\n\t [[node save_1/RestoreV2 (defined at C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:147) ]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import requests\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import ItalianStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tflearn import input_data, fully_connected, regression, DNN\n",
    "\n",
    "from flask import Flask, request\n",
    "\n",
    "TOKEN = \"EAAOTXsXg5kwBAIXtxYKiPSKZA3BxV9pxZBDXZBrmCrW6I4qi2VbToKtgm1I1XzaOUfz1RjgBNOziza3oKZCSWlBzxM0axkjOE9IZAlYB4vhI4IJJMFOuBpGSlOUfnIH8iBF6DQ1UZCVFuYPiLvZBCADN8r4cJmtIKthTfsF0ZADC6AZDZD\"\n",
    "\n",
    "# istanzio un'applicazione Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# leggo i dati dal corpus\n",
    "d = pickle.load(open(\"corpus.p\", \"rb\"))\n",
    "temi = d['temi']\n",
    "classi = d['classi']\n",
    "documenti = d['documenti']\n",
    "\n",
    "# mi connetto al db\n",
    "database = \"bot.db\"\n",
    "conn = sqlite3.connect(database)\n",
    "cursor = conn.cursor()\n",
    "stemmer = ItalianStemmer()\n",
    "stop = set(stopwords.words('italian'))\n",
    "\n",
    "def genera_temi(testo):\n",
    "    stop = set(stopwords.words('italian'))\n",
    "    lista_parole = word_tokenize(testo)\n",
    "    temi = [\n",
    "        stemmer.stem(p.lower()) for p in lista_parole\n",
    "        if p not in stop and p not in string.punctuation\n",
    "    ]\n",
    "    return temi\n",
    "\n",
    "def genera_input(lista_temi):\n",
    "    lista_input = [0] * len(temi)\n",
    "    for tema in lista_temi:\n",
    "        for i, t in enumerate(temi):\n",
    "            if t == tema:\n",
    "                lista_input[i] = 1\n",
    "    return (np.array(lista_input))\n",
    "\n",
    "def BotANN(): \n",
    "    tf.reset_default_graph()\n",
    "    rete = input_data(shape=[None, len(temi)])\n",
    "    rete = fully_connected(rete, 8)\n",
    "    rete = fully_connected(rete, 8)\n",
    "    rete = fully_connected(rete, len(classi), activation='softmax')\n",
    "    rete = regression(rete)\n",
    "    model = DNN(rete, tensorboard_dir='logs')\n",
    "    return model\n",
    "\n",
    "modello = BotANN()\n",
    "modello.load(\"./rete\")\n",
    "\n",
    "SOGLIA_ERRORE = 0.25\n",
    "\n",
    "def classifica(modello, array):\n",
    "    # genera le probabilità\n",
    "    prob = modello.predict([array])[0]\n",
    "    # filtro quelle che superano la soglia\n",
    "    risultati = [\n",
    "        [i,p] for i,p in enumerate(prob)\n",
    "        if p > SOGLIA_ERRORE\n",
    "    ]\n",
    "    # ordino per le classi più probabili\n",
    "    risultati.sort(key=lambda x: x[1], reverse=True)\n",
    "    lista_classi = []\n",
    "    for r in risultati:\n",
    "        lista_classi.append((list(classi)[r[0]], r[1]))\n",
    "    return lista_classi\n",
    "\n",
    "def invia(utente, messaggio):\n",
    "    params = {\n",
    "        \"access_token\": TOKEN\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = json.dumps({\n",
    "            \"recipient\": {\n",
    "                \"id\": utente\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"text\": messaggio\n",
    "            }\n",
    "    })\n",
    "    requests.post(\n",
    "        \"https://graph.facebook.com/v2.6/me/messages\",\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "        data=data\n",
    "    )\n",
    "    \n",
    "def elabora_risposta(frase, utente=\"utente_prova\"):\n",
    "    temi_frase = genera_temi(frase)\n",
    "    X = genera_input(temi_frase)\n",
    "    classi_predette = classifica(modello, X)\n",
    "    # tolgo le probabilità\n",
    "    classi_predette = [c[0] for c in classi_predette]\n",
    "    if classi_predette:\n",
    "        # ho un contesto settato?\n",
    "        if contesti.get(utente):\n",
    "            contesto = contesti[utente]\n",
    "            # quali classi hanno questo contesto?\n",
    "            q = \"\"\"\n",
    "                SELECT classe FROM classi\n",
    "                INNER JOIN contesti ON (classi.id = contesti.id_classe)\n",
    "                WHERE classe IN ({})\n",
    "                \"\"\".format(\",\".join(\n",
    "                    \"'{}'\".format(classe) for classe in classi_predette\n",
    "            )\n",
    "            )\n",
    "            filtro_classi = [c[0] for c in cursor.execute(q).fetchall()]\n",
    "            if filtro_classi:\n",
    "                # ho almeno una classe predetta che usa un contesto\n",
    "                classi_predette = [c for c in classi_predette]\n",
    "                \n",
    "        # leggo le risposte\n",
    "        q = \"\"\"\n",
    "            SELECT risposta\n",
    "            FROM risposte\n",
    "            INNER JOIN classi ON (risposte.id_classe = classi.id)\n",
    "            WHERE classe = '{0}'\n",
    "        \"\"\".format(classi_predette[0])\n",
    "        risposte = [r[0] for r in cursor.execute(q).fetchall()]\n",
    "        \n",
    "        # scelgo una risposta\n",
    "        risposta = np.random.choice(risposte)\n",
    "        \n",
    "        # imposto il contesto, se c'è\n",
    "        q = \"\"\"\n",
    "            SELECT contesto from contesti\n",
    "            INNER JOIN classi ON (contesti.id_classe = classi.id)\n",
    "            INNER JOIN risposte ON (risposte.id_classe = classi.id)\n",
    "            WHERE risposta = \"{}\"\n",
    "        \"\"\".format(risposta)\n",
    "        contesto = cursor.execute(q).fetchone()\n",
    "        contesti[utente] = contesto[0] if contesto else None\n",
    "        \n",
    "        return risposta\n",
    "    \n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def risponditore():\n",
    "    if request.method == 'GET':\n",
    "        # Quando registriamo un endpoint a un webhook, dobbiamo\n",
    "        # restituire la 'hub.challenge', un parametro che\n",
    "        # serve a Facebook.\n",
    "        if request.args.get(\"hub.mode\") == \"subscribe\" and \\\n",
    "        request.args.get(\"hub.challenge\"):\n",
    "            if not request.args.get(\"hub.verify_token\") == TOKEN:\n",
    "                return \"Token errato\", 403\n",
    "            return request.args[\"hub.challenge\"], 200\n",
    "        \n",
    "        return \"Sono un bot, non un sito web\", 200\n",
    "    elif request.method == 'POST':\n",
    "        # è appena arrivato un messaggio\n",
    "        data = request.get_json()\n",
    "        if data[\"object\"] == \"page\":\n",
    "            for entry in data[\"entry\"]:\n",
    "                for messaging_event in entry[\"messaging\"]:\n",
    "                    utente = messaging_event[\"sender\"][\"id\"]\n",
    "                    domanda = messaging_event[\"message\"][\"text\"]\n",
    "                    risposta = elabora_risposta(domanda, utente)\n",
    "                    invia(utente, risposta)\n",
    "        return \"ho risposto\", 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
